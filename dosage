#!/usr/bin/env python
# -*- coding: iso-8859-1 -*-

# Dosage, the webcomic downloader
# Copyright (C) 2004-2005 Tristan Seligmann and Jonathan Jacobs
# Copyright (C) 2012 Bastian Kleineidam
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of version 2 of the GNU General Public License as
# published by the Free Software Foundation.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
from __future__ import print_function
import sys
import os
import optparse

from dosagelib import events, scraper
from dosagelib.output import out
from dosagelib.util import get_columns, internal_error, getDirname
from dosagelib.configuration import App, Freeware, Copyright, SupportUrl

def setupOptions():
    """Construct option parser.
    @return: new option parser
    @rtype optparse.OptionParser
    """
    usage = 'usage: %prog [options] comicModule [comicModule ...]'
    parser = optparse.OptionParser(usage=usage)
    parser.add_option('-v', '--verbose', action='count', dest='verbose', default=0, help='provides verbose output, use multiple times for more verbosity')
    parser.add_option('-n', '--numstrips', action='store', dest='numstrips', type='int', default=0, help='traverse and retrieve the given number of comic strips; use --all to retrieve all comic strips')
    parser.add_option('-a', '--all', action='store_true', dest='all', default=None, help='traverse and retrieve all comic strips')
    parser.add_option('-b', '--basepath', action='store', dest='basepath', default='Comics', help='set the path to create invidivual comic directories in, default is Comics', metavar='PATH')
    parser.add_option('--baseurl', action='store', dest='baseurl', default=None, help='the base URL of your comics directory (for RSS, HTML, etc.); this should correspond to --base-path', metavar='PATH')
    parser.add_option('-l', '--list', action='store_const', const=1, dest='list', help='list available comic modules')
    parser.add_option('--singlelist', action='store_const', const=2, dest='list', help='list available comic modules in a single list')
    parser.add_option('-V', '--version', action='store_true', dest='version', help='display the version number')
    parser.add_option('-m', '--modulehelp', action='store_true', dest='modhelp', help='display help for comic modules')
    parser.add_option('-t', '--timestamps', action='store_true', dest='timestamps', default=False, help='print timestamps for all output at any info level')
    parser.add_option('-o', '--output', action='store', dest='output', choices=events.getHandlers(), help='output formatting for downloaded comics')
    parser.add_option('--adult', action='store_true', dest='adult', default=False, help='confirms that you are old enough to view adult content')
    return parser


def displayVersion():
    """Display application name, version, copyright and license."""
    print(App)
    print(Copyright)
    print(Freeware)
    print("For support see", SupportUrl)
    return 0


def setOutputInfo(options):
    """Set global output level and timestamp option."""
    out.level = 0
    out.level += options.verbose
    out.timestamps = options.timestamps


def saveComicStrip(strip, basepath):
    """Save a comic strip which can consist of multiple images."""
    errors = 0
    allskipped = True
    for image in strip.getImages():
        try:
            filename, saved = image.save(basepath)
            if saved:
                allskipped = False
        except IOError as msg:
            out.error('Could not save %s: %s' % (image.filename, msg))
            errors += 1
    return errors, allskipped


def displayHelp(comics, basepath):
    """Print help for comic strips."""
    try:
        for scraperobj in getScrapers(comics, basepath):
            for line in scraperobj.getHelp().splitlines():
                out.info("Help: "+line)
    except ValueError as msg:
        out.error(msg)
        return 1
    return 0


def getComics(options, comics):
    """Retrieve given comics."""
    errors = 0
    if options.output:
        events.installHandler(options.output, options.basepath, options.baseurl)
    events.getHandler().start()
    for scraperobj in getScrapers(comics, options.basepath, options.adult):
        out.context = scraperobj.get_name()
        if options.all:
            strips = scraperobj.getAllStrips()
        elif options.numstrips:
            strips = scraperobj.getAllStrips(options.numstrips)
        else:
            strips = scraperobj.getCurrentStrips()
        first = True
        try:
            for strip in strips:
                _errors, skipped = saveComicStrip(strip, options.basepath)
                errors += _errors
                if not first and scraperobj.indexes:
                    # stop when indexed retrieval skipped all images for one
                    # comie strip (except the first one)
                    out.info("Stop retrieval because image file already exists")
                    break
                first = False
        except (ValueError, IOError) as msg:
            out.error(msg)
            errors += 1
            continue
    events.getHandler().end()
    return errors


def run(options, comics):
    """Execute comic commands."""
    setOutputInfo(options)
    if options.version:
        return displayVersion()
    if options.list:
        return doList(options.list == 1)
    if len(comics) <= 0:
        out.warn('No comics specified, bailing out!')
        return 1
    if options.modhelp:
        return displayHelp(comics, options.basepath)
    return getComics(options, comics)


def doList(columnList):
    """List available comics."""
    out.info('Available comic scrapers:')
    scrapers = getScrapers(['@@'])
    if columnList:
        num = doColumnList(scrapers)
    else:
        num = doSingleList(scrapers)
    out.info('%d supported comics.' % num)
    return 0


def doSingleList(scrapers):
    """Get list of scraper names, one per line."""
    for num, scraperobj in enumerate(scrapers):
        print(scraperobj.get_name())
    return num


def doColumnList(scrapers):
    """Get list of scraper names with multiple names per line."""
    screenWidth = get_columns(sys.stdout)
    names = [scraperobj.get_name() for scraperobj in scrapers]
    num = len(names)
    maxlen = max([len(name) for name in names])
    namesPerLine = int(screenWidth / (maxlen + 1))
    while names:
        print(''.join([name.ljust(maxlen) for name in names[:namesPerLine]]))
        del names[:namesPerLine]
    return num


def getScrapers(comics, basepath=None, adult=True):
    """Get scraper objects for the given comics."""
    if '@' in comics:
        # only scrapers whose directory already exists
        if len(comics) > 1:
            out.warn("using '@' as comic name ignores all other specified comics.")
        for scraperclass in scraper.get_scrapers():
            if not adult and scraperclass.adult:
                out.warn("skipping adult comic %s" % scraperclass.get_name())
                continue
            dirname = getDirname(scraperclass.get_name())
            if os.path.isdir(os.path.join(basepath, dirname)):
                yield scraperclass()
    elif '@@' in comics:
        # all scrapers
        for scraperclass in scraper.get_scrapers():
            if not adult and scraperclass.adult:
                out.warn("skipping adult comic %s" % scraperclass.get_name())
                continue
            yield scraperclass()
    else:
        # get only selected comic scrapers
        # store them in a list to catch naming errors early
        scrapers = []
        for comic in comics:
            if ':' in comic:
                name, index = comic.split(':', 1)
                indexes = index.split(',')
            else:
                name = comic
                indexes = None
            scraperclass = scraper.get_scraper(name)
            if not adult and scraperclass.adult:
                out.warn("skipping adult comic %s" % scraperclass.get_name())
                continue
            scrapers.append(scraperclass(indexes=indexes))
        for s in scrapers:
            yield s


def main():
    """Parse options and execute commands."""
    try:
        parser = setupOptions()
        options, args = parser.parse_args()
        # eliminate duplicate comic names
        comics = set(args)
        res = run(options, comics)
    except KeyboardInterrupt:
        print("Aborted.")
        res = 1
    except Exception:
        internal_error()
        res = 2
    return res


def profile():
    """Profile the loading of all scrapers."""
    import cProfile
    cProfile.run("scraper.get_scrapers()", "dosage.prof")


def viewprof():
    """View profile stats."""
    import pstats
    stats = pstats.Stats("dosage.prof")
    stats.strip_dirs().sort_stats("cumulative").print_stats(100)


if __name__ == '__main__':
    sys.exit(main())
    #profile()
    #viewprof()
